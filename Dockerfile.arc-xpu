# This is a modified Dockerfile based on the official Intel Dockerfiles so that
# it works for Whisper +  Intel ARC cards. The image is located at:
# https://github.com/intel/intel-extension-for-pytorch/blob/main/docker/README.md
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

ARG UBUNTU_VERSION=22.04

FROM ubuntu:${UBUNTU_VERSION}

ENV LANG=C.UTF-8

ARG DEBIAN_FRONTEND=noninteractive

RUN apt update && \
    apt install -y --no-install-recommends --fix-missing \
    apt-utils \
    build-essential \
    ca-certificates \
    clinfo \
    curl \
    git \
    libjpeg-dev \
    libpng-dev \
    gnupg2 \
    gpg-agent \
    rsync \
    sudo \
    ffmpeg \
    unzip \
    wget && \
    apt-get clean && \
    rm -rf  /var/lib/apt/lists/*

ARG DEVICE=arc

RUN no_proxy=$no_proxy wget -qO - https://repositories.intel.com/graphics/intel-graphics.key | \
    gpg --dearmor --output /usr/share/keyrings/intel-graphics.gpg
RUN printf 'deb [arch=amd64 signed-by=/usr/share/keyrings/intel-graphics.gpg] https://repositories.intel.com/graphics/ubuntu jammy %s\n' "$DEVICE" | \
    tee  /etc/apt/sources.list.d/intel.gpu.jammy.list

RUN apt update && \
    apt install -y --no-install-recommends --fix-missing \
    intel-opencl-icd \
    intel-level-zero-gpu \
    level-zero \
    level-zero-dev && \
    apt-get clean && \
    rm -rf  /var/lib/apt/lists/*

RUN no_proxy=$no_proxy wget -O- https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB \
   | gpg --dearmor | tee /usr/share/keyrings/oneapi-archive-keyring.gpg > /dev/null && \
   echo "deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main" \
   | tee /etc/apt/sources.list.d/oneAPI.list

RUN apt update && \
    apt install -y --no-install-recommends --fix-missing \
    intel-basekit \
    intel-oneapi-runtime-dpcpp-cpp \
    intel-oneapi-runtime-mkl \
    intel-oneapi-runtime-ccl

ARG PYTHON=python3.10
RUN apt update && apt install -y software-properties-common 
RUN add-apt-repository -y ppa:deadsnakes/ppa 

RUN apt-cache policy $PYTHON && apt update && apt install -y \
    --no-install-recommends --fix-missing $PYTHON 

RUN apt update && apt install -y --no-install-recommends --fix-missing \
    ${PYTHON} lib${PYTHON} python3-pip ${PYTHON}-distutils && \
    apt-get clean && \
    rm -rf  /var/lib/apt/lists/*

RUN pip --no-cache-dir install --upgrade \
    pip \
    setuptools

RUN ln -sf $(which ${PYTHON}) /usr/local/bin/python && \
    ln -sf $(which ${PYTHON}) /usr/local/bin/python3 && \
    ln -sf $(which ${PYTHON}) /usr/bin/python && \
    ln -sf $(which ${PYTHON}) /usr/bin/python3

ARG TORCH_VERSION=2.0.1a0
ARG TORCHVISION_VERSION=0.15.2a0
ARG IPEX_VERSION=2.0.110+xpu
ARG ONECCL_BIND_PT_VERSION="N/A"
ARG INTEL_WHL_URL=https://developer.intel.com/ipex-whl-stable-xpu
ARG ONECCL_BIND_PT_WHL_URL="N/A"

RUN python -m pip install numpy

RUN export INTEL_WHL_URL_RES=`curl -Ls -o /dev/null -w %{url_effective} ${INTEL_WHL_URL}` && export INTEL_WHL_HOST=`echo $INTEL_WHL_URL_RES | awk -F/ '{print $3}'` && \
    python -m pip install torch==${TORCH_VERSION} -f $INTEL_WHL_URL_RES --trusted-host $INTEL_WHL_HOST && \
    python -m pip install intel_extension_for_pytorch==${IPEX_VERSION} -f $INTEL_WHL_URL_RES --trusted-host $INTEL_WHL_HOST && \
    python -m pip install torchvision==${TORCHVISION_VERSION} -f $INTEL_WHL_URL_RES --trusted-host $INTEL_WHL_HOST

RUN if [ ${ONECCL_BIND_PT_VERSION} != "N/A" ] && [ ${ONECCL_BIND_PT_WHL_URL} != "N/A" ]; then \
        python -m pip install oneccl_bind_pt==${ONECCL_BIND_PT_VERSION} -f ${ONECCL_BIND_PT_WHL_URL}; \
    fi

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/oneapi/tbb/2021.11/env/../lib/intel64/gcc4.8:/opt/intel/oneapi/mpi/2021.11/opt/mpi/libfabric/lib:/opt/intel/oneapi/mpi/2021.11/lib:/opt/intel/oneapi/mkl/2024.0/lib:/opt/intel/oneapi/ippcp/2021.9/lib/:/opt/intel/oneapi/ipp/2021.10/lib:/opt/intel/oneapi/dpl/2022.3/lib:/opt/intel/oneapi/dnnl/2024.0/lib:/opt/intel/oneapi/debugger/2024.0/opt/debugger/lib:/opt/intel/oneapi/dal/2024.0/lib:/opt/intel/oneapi/compiler/2024.0/opt/oclfpga/host/linux64/lib:/opt/intel/oneapi/compiler/2024.0/opt/compiler/lib:/opt/intel/oneapi/compiler/2024.0/lib:/opt/intel/oneapi/ccl/2021.11/lib/:/opt/intel/oneapi/lib:/opt/intel/oneapi/lib/intel64::/opt/intel/oneapi/mkl/latest/lib/intel64:/opt/intel/oneapi/compiler/latest/linux/compiler/lib/intel64_lin:/opt/intel/oneapi/compiler/latest/linux/lib
ENV ONEAPI_ROOT=/opt/intel/oneapi
ENV DPCPPROOT=${ONEAPI_ROOT}/compiler/latest
ENV MKLROOT=${ONEAPI_ROOT}/mkl/latest
# ONEDNN_LAYOUT must be 0 for whisper else it crashes (why?!?)
ENV IPEX_XPU_ONEDNN_LAYOUT=0  

RUN . ${ONEAPI_ROOT}/setvars.sh

RUN apt update && \
    apt install -y sudo 

COPY poetry.lock /deps/
COPY pyproject.toml /deps/

# install an XPU patched version of OpenAI Whisper and the whisper-asr-webservice
RUN pip install poetry==1.6.1 setuptools wheel && \
	pip install --upgrade git+https://github.com/leuc/whisper.git@b4bc9b280a2db1515782e0d68a02f90cebcd438e && \
	export PATH=$PATH:/home/user/.local/bin && \
	git clone https://github.com/ahmetoner/whisper-asr-webservice.git app && \
	cd app && git checkout 51c6eceda0836d145048224693c69c2706d78f46 && \
	rm poetry.lock pyproject.toml && cp /deps/* ./ && \
	poetry config virtualenvs.create false && \
	poetry lock && poetry install --no-interaction && \
	apt-get clean && \
	rm -rf  /var/lib/apt/lists/*

ENTRYPOINT ["gunicorn", "--bind", "0.0.0.0:9000", "--workers", "1", "--timeout", "0", "app.webservice:app", "-k", "uvicorn.workers.UvicornWorker"]
